# Understand the problem
The most important thing is understand the problem you are working on, and the key things for machine learning problem are:
- What are the ***independent variables***?
- What is the ***dependent variable*** (what you need to predict)?

# Understand and explore the data
- Random sample the data and understand the data:
  - What is the data type?
  - What is the value (value range)?
  - Does it have NA value?

Tips: in linux, you could use the `shuf` tool. Example: `shuf -n 10 -o sample.tsv input_src.tsv`

- If training data covers very long period data, and your task is trying to predict future (next n weeks/months), you might want to start with the most recent data and do a study there first.
  - For example, you could build a very naive *baseline* with using the avg value from the past n weeks/months as the prediction value.
- Spend a bit of time to run through the data preprocessing on the small smaple set first, make sure all work well and reasonable, then go back and run on the whole set.

### Other tips about data normalize
- Generate the NA dictionary base on the large dataset, and could apply it to the created small set later. If the subset is from different dataset and has different missing columns, it needs to update the dictionary. **Always try to keep track of the missing columns**

# Importance of good validation set
Without good validation set, it is hard/impossible to build a good model.

## How to verify it is a good validation set?

Try to use teh test set to calibrate the validation set.
- Run the models on the validation set and the test set. If the scores on the validation set and the test set are relative/linear, then it means that the validation set is good.
- The models don't need to be very good fine-tuned models, but any (simple) models. The goal is to calibrate the validation set.
  
## What scenarios (context) do we need to use this method?
- It is not easy to run the model on the test set, including but not limit to:
  - Time cost (say take long time to run the test set)
  - Limit runs on the test set, like in the competition.
  - Environment limitation. Like the online measurment (final test) and offline measurement (model development/offline test).

Generally, not just in the competiion, but the ML project, this tech is very useful since it provides more flexible for you to run the experiment quickly and continuously improve the model with the fast feedbacks.

## How to construct good evaluation set (as close to the test set)?
Several tips:
- Close by date (i.e. most recent) 
- Plot lots of pictures.

# Interprete machine learning models

When interprete the model, we don't need to use the full dataset, instead just a small set which could indicate the nature of relationships.

## Understand the prediction
When predict the value, we might also want to know how confident the prediction is.

*How to know the confidence?*
Generally, it is less confident if the prediction does not have many sample like it.

From the random forest perspective, if the prediction in different trees are in very different places, it will has less confidence. That is the **standard devidation (variance) of the predictions of the trees is more representative than the mean. That is, it gives us relative understanding of how confident the prediciton is.**.

# Feature importance
It will be a good practice to look into the feature importance first in practice, say build the random forest model ASAP and look into the importance features.

*How well the random forest should be enough for looking into important features?* It is significantly better than random, but not necessary much better than that.

*How many important features to pick to look into?*
Usually, top 10 would be enough. But it depends on the total features, if you have other than 1000 features for the very complicated model, say search ranking, then you might need to look into the top 100.

Another suggestion is that, you could plot the distribution of the feature importance.

Once you looked into the feature importance, you could check with the owner or domain expert to understand what is that column.


## Reference
- https://course18.fast.ai/ml
- https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-3-fa4065d8cb1e
